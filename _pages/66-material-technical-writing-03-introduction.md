---
layout: page
title: Introduction 작성 방법
permalink: /lecture/material/intro-technical-writing/introduction
image: CUK_4Seasons.jpg
description: 논문의 Introduction(서론)은 독자와 심사위원이 가장 먼저 접하는 본문 파트입니다. AI 논문에서는 기술적 내용이 매우 방대하므로, 서론에서 핵심 포인트를 선명하게 잡아주는 것이 더욱 중요합니다.
toc: true
toc_sticky: true
toc_label: "Table of Contents"
---

논문의 Introduction(서론)은 **독자**와 **심사위원**이 가장 먼저 접하는 본문 파트입니다.  
특히 **AI(인공지능) 논문**에서 서론은 다음과 같은 역할을 합니다:

1. **연구 문제와 동기 부여**: 왜 이 연구가 중요한지, 무엇이 문제인지.  
2. **선행 연구 대비 차별성**: 기존 알고리즘/모델/방법론이 가진 한계를 어떻게 보완하는지.  
3. **논문의 목표와 기여(Contribution)**: 새로 제안하는 모델, 이론, 실험 설계 등의 가치를 짧게 요약.  
4. **논문 전체 구조 안내**: “이후 섹션에서 어떤 내용이 전개될지”를 간략히 미리 알려주기.

AI 논문에서는 **기술적 내용**이 매우 방대하므로, 서론에서 **핵심 포인트**를 선명하게 잡아주는 것이 더욱 중요합니다.

---

## 1. Introduction의 중요성

1. **연구 맥락(Context) 제시**  
   - AI 분야는 속도도 빠르고 전문 영역이 세분화되어 있습니다. 독자가 **“왜 이 연구가 필요한가”**를 이해하도록, 전체 맥락을 서론에서 잡아줘야 합니다.  
   - 예) “최근 Transformer 계열 모델이 NLP 영역에서 큰 발전을 보였지만, 저자원 언어(low-resource) 환경에서는 여전히 제약이 많다.”

2. **기술적 디테일 이전에 ‘왜?’에 답하기**  
   - 방법론(Proposed Method) 섹션으로 바로 들어가기 전에, **“왜 이 문제를 다루는지”**를 충분히 설득해야 합니다.  
   - AI 논문 심사위원은 특히 “연구 주제가 실제로 중요한가?”, “의미 있는 난제를 다루고 있는가?”를 먼저 체크합니다.

3. **문제 정의와 기여도(Contribution) 강조**  
   - “성능이 조금 좋아졌다” 정도로는 탑티어 학회(NeurIPS, ICML, CVPR 등)에서 주목받기 어렵습니다.  
   - 서론에서 **연구가 가져올 학술적/산업적 임팩트**를 간단히 보여주면, 독자가 다음 섹션을 읽을 동기가 생깁니다.

---

## 2. Introduction 기본 구성

대체로 **3~5단락** 정도로 구성하며, 다음 요소들을 포함합니다:

1. **배경(Background) & 현황(Overview)**  
   - 연구 분야(예: 컴퓨터비전, NLP, 강화학습)의 **현재 트렌드**나 **핵심 문제**를 간략히 정리  
   - 예) “최근 Diffusion 모델이 이미지 생성 작업에서 기존 GAN 대비 우수한 성능을 보이고 있다.”

2. **연구 격차(Research Gap) & 문제 정의**  
   - 기존 연구(선행 연구)의 한계점, 해결되지 않은 이슈, 미흡한 부분 등  
   - 예) “하지만 Diffusion 모델은 고해상도 이미지 생성 시 연산량이 폭발적으로 증가한다는 한계가 있다.”

3. **본 논문의 목표(Research Question) & 기여(Contribution)**  
   - 연구 목표를 구체적으로 제시하고, 어떤 접근으로 문제를 해결하려 하는지 요약  
   - 예) “본 논문에서는 가변 길이 채널링 방법(Variable Channeling)을 제안해, 고해상도 이미지 처리 시 연산 효율을 높이고자 한다.”  
   - 연구 기여(3~4가지 포인트)를 **볼드체**, **번호** 등으로 정리해 주면 가독성이 좋습니다.

4. **결과 요약(핵심 성과)**  
   - 제안 기법을 적용했을 때, 얻은 **정량적 결과**를 짧게 언급(예: “ImageNet 고해상도 테스트에서 기존 대비 +1.5% FID 향상”)  
   - 혹은 “추론 속도 2배 빨라짐”, “메모리 사용량 30% 절감” 등.  
   - 인상적인 성과를 한두 문장으로 제시하면, 독자 입장에서 **흥미**를 느끼기 쉽습니다.

5. **논문 구성 안내**  
   - 마지막 문단에서 “이후 섹션은 다음과 같이 구성되어 있다. 2장에서는 … 3장에서는 …” 식으로 간단히 정리  
   - AI 논문은 구조가 길고 복잡하기 때문에, 독자 입장에서 **본문을 추적**하기 쉬워집니다.

---

## 3. (예시) Introduction의 단락별 흐름

**\[1단락: AI 배경 & 문제 상황\]**  
최근 **Transformers** 계열의 딥러닝 모델이 다양한 **자연어처리(NLP)** 과제에서 높은 정확도를 달성하고 있다. 특히 **BERT**, **GPT** 등의 모델은 대규모 코퍼스 학습으로 기존 방식과 차원이 다른 성능을 보여주었다. 그러나 대부분의 연구는 **영어**를 비롯한 리소스가 풍부한 언어에서 진행되었으며, **저자원 언어**에서는 제대로 된 모델 학습이 어려운 상황이다.

**\[2단락: 기존 연구(선행연구)와 한계\]**  
예컨대, Kim 등(2021)은 소량의 병렬 코퍼스만을 이용해 세그먼트 기반 Transformer를 적용하는 시도를 했으나, 토큰화 문제로 인한 성능 저하가 존재했다. 또한 Lee 등(2022)은 멀티링구얼(Multilingual) 모델로 접근했으나, 희소 데이터 문제를 완전히 해결하지 못했다. 이처럼 **저자원 언어 학습**에 대한 효과적인 프레임워크가 아직 부족한 실정이다.

**\[3단락: 본 연구의 목표와 기여(문장 분리 제시)\]**  
본 논문에서는 **저자원 언어 환경**에서도 우수한 성능을 내는 **Domain-aware Self-Supervised Pretraining(DA-SSP)** 기법을 제안한다. 구체적으로,  
1. **문장 단위 클러스터링**을 통해 도메인별 특징을 자동 추출하고,  
2. **Masked Language Modeling** 기법과 결합해 **비지도 사전학습(unsupervised pretraining)**을 수행하며,  
3. **다양한 저자원 언어코퍼스(한국어, 태국어, 스와힐리 등)**를 사용해 실제 적용 가능성을 검증했다.

**\[4단락: 주요 결과 및 의의\]**  
우리의 기법을 적용했을 때, 3개 저자원 언어에서 **기존 멀티링구얼 모델 대비 평균 BLEU +2.3pt**의 성능 개선을 확인할 수 있었다. 또한 도메인 특화 알고리즘으로 인해 **학습 속도**가 약 1.5배 빨라지는 장점이 있다. 이는 국내외 기업이나 기관에서 저자원 언어 데이터를 다룰 때 **실질적인 비용 절감**과 **모델 확장성** 측면에서 기여할 수 있을 것으로 기대된다.

**\[5단락: 논문 구조 안내\]**  
남은 섹션은 다음과 같이 구성된다. **2장**에서 선행 연구와 이론적 배경을, **3장**에서 제안 기법(DA-SSP)을 상세히 설명한다. **4장**에서는 실험 프로토콜과 결과를 제시하고, **5장**에서 결과 분석과 한계를 논의한다. 마지막으로 **6장**에서 결론과 향후 연구 과제를 제안한다.

---

## 4. 서론에서 주의할 점

1. **너무 많은 기술적 디테일을 서론에 넣지 말 것**  
   - 모델 구조, 알고리즘 단계 등을 **서론에 장황히 풀어놓으면** 독자와 심사위원이 **헷갈리거나 지루**해질 수 있습니다.  
   - 서론은 **“큰 그림”**과 **“기여 요약”**을 하는 곳, 구체적 기술 설명은 **Method** 파트에서.

2. **관련 연구(Reference) 무작정 나열 금지**  
   - AI 논문의 선행 연구 파트는 보통 2장(Related Work)에서 좀 더 체계적으로 다룹니다.  
   - 서론에서는 “어떤 흐름 속에서 본 연구가 나오게 되었는지”를 **핵심 참고문헌** 위주로 짧게 언급합니다.

3. **추정·주관적 평가**에 대한 근거 제시  
   - 예: “기존 방식은 데이터가 부족하면 쓸모가 없다.”라는 주장이 있다면, “어떤 논문에서 어떤 근거로 그렇게 밝혀졌다”거나, “직접 실험한 결과” 등을 **간단히** 첨언하세요.  
   - AI 리뷰어들은 “단순 의견이 아니라, **실험적·이론적** 근거가 있는지”를 확인합니다.

4. **숫자나 용어 사용 시 정확도 유지**  
   - “약 2배 빠르다” → “파이썬 기반 벤치마크에서 2.1배 더 빠름” 정도로 구체적 숫자를 적으면 신뢰도가 올라갑니다.  
   - AI 분야의 용어는 특정 의미가 확고한 경우가 많으므로, **공식 용어**를 정확히 쓰거나, 처음 등장 시 **약어(Abbreviation) 정의**를 해두세요.

---

## 5. 한눈에 보는 서론 작성 체크리스트

1. **문제 상황, 필요성**  
   - [ ] AI 특정 분야(컴퓨터비전, NLP, RL 등)의 현황을 1~2문단으로 간결히 정리했는가?  
   - [ ] 왜 이 이슈가 중요한지(산업적/학술적 임팩트)를 독자에게 어필했는가?

2. **선행 연구와 한계**  
   - [ ] 기존 방법들이 어떤 한계를 지니는지, 구체적 예시나 통계를 제시했는가?  
   - [ ] 너무 자세히 나열하지 않고, 핵심 레퍼런스 위주로 요약했는가?

3. **본 연구의 목표와 기여**  
   - [ ] 제안 방법 혹은 연구 아이디어를 한두 문장으로 핵심만 표현했는가?  
   - [ ] 연구 기여(3~4가지만) 간략히 나열, 볼드 처리 또는 번호 매기기 등을 활용했는가?

4. **성과(결과) 요약**  
   - [ ] 성능 향상 수치나 장점(속도, 정확도 등)을 간략히 언급했는가?  
   - [ ] 향후 응용이나 산업적 가치 등, 의의를 짧게 덧붙였는가?

5. **논문 구조 안내**  
   - [ ] “2장에서는 …, 3장에서는 …” 식으로, 후속 섹션 구성을 한 문단으로 언급했는가?

---

## 6. 결론

AI 논문의 **Introduction**은 단순한 도입부가 아니라, **연구 가치를 압축적으로 보여주는 창구**입니다.  
- **문제 제기 → 선행 연구 한계 → 연구 기여 → 핵심 성과 → 본문 구조**  
이 다섯 단계를 **명확하고 간결**하게 제시하면, 논문의 전문성과 설득력이 크게 높아집니다.

---

## 참고 자료

- *Creswell, J. W. (2014). Research Design: Qualitative, Quantitative, and Mixed Methods Approaches.*  
- *NeurIPS / ICML / ICLR Author Guidelines* (각 학회별 홈페이지)  
- *Overleaf Tutorial: Writing a Compelling Introduction for Computer Science Papers*

---

