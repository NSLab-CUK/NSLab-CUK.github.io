---
layout: page
title: AI-CUK Joint Journal Club
permalink: /joint-journal-club/
image: CUK_4Seasons.jpg
toc: true
toc_sticky: true
toc_label: "Table of Contents"
---

<h5>Table of Contents</h5>
* TOC
{:toc}


***
### Spring 2023

***
##### Jan 31th, 2023
{:.no_toc}

* V.T.Hoang, Review on "Universal Graph Transformer Self-Attention Networks", WWW 2022
<iframe src="https://www.slideshare.net/slideshow/embed_code/key/FYG93IsI2mJhQV?hostedIn=slideshare&page=upload" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

***
##### Jan 10th, 2023
{:.no_toc}

* S.T.Nguyen, Review on "Do Transformers Really Perform Bad for Graph Representation?", NeurIPS 2021
<p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/l4shGXsWXsR3RM?hostedIn=slideshare&page=upload" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen></iframe></p>

***
##### Jan 3rd, 2023
{:.no_toc}

* V.T.Hoang, Review on "Global Self-Attention as a Replacement for Graph Convolution", KDD 2022
<p align="center"><iframe src="//www.slideshare.net/slideshow/embed_code/key/wGuUO1CzX1z6fV" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe></p>
