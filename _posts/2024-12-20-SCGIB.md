---
layout: post
title:  S-CGIB, A Novel Pre-trained Graph Neural Network in Molecular Structure Learning
date:   2024-12-20 00:00:00 +0900
image:  Bib_Network.png
tags:   Release
published: true
description: The Network Science Lab at the Catholic University of Korea releases S-CGIB, a Novel Pre-trained Graph Neural Network in Molecular Structure Learning
---

We present [S-CGIB](https://github.com/NSLab-CUK/S-CGIB), a novel Architecture for Pre-training Graph Neural Networks in Molecular Structure Learning and developed by NS Lab, CUK based on pure PyTorch backend. The paper has been accepted for presentation at the AAAI 2025 conference.

<p align="center">
  <img src="/images/SCGIB.jpg" alt="Subgraph-conditioned Graph Information Bottleneck" width="800">
  <br>
  <b></b> The overall architecture of Subgraph-conditioned Graph Information Bottleneck.
</p>

We aim to build a pre-trained Graph Neural Network (GNN) model on molecules without human annotations or prior knowledge. Although various attempts have been proposed to overcome limitations in acquiring labeled molecules, the previous pre-training methods still rely on semantic subgraphs, i.e., functional groups. Only focusing on the functional groups could overlook the graph-level distinctions. The key challenge to build a pre-trained GNN on molecules is how to (1) generate well-distinguished graph-level representations and (2) automatically discover the functional groups without prior knowledge. To solve it, we propose a novel Subgraph-conditioned Graph Information Bottleneck, named S-CGIB, for pre-training GNNs to recognize core subgraphs (graph cores) and significant subgraphs. The main idea is that the graph cores contain compressed and sufficient information that could generate well-distinguished graph-level representations and reconstruct the input graph conditioned on significant subgraphs across molecules under the S-CGIB principle. To discover significant subgraphs without prior knowledge about functional groups, we propose generating a set of functional group candidates, i.e., ego networks, and using an attention-based interaction between the graph core and the candidates. Despite being identified from self-supervised learning, our learned subgraphs match the real-world functional groups. Extensive experiments on molecule datasets across various domains demonstrate the superiority of S-CGIB.




## A short description of S-CGIB:

- S-CGIB is trained to generate well-distinguished graph-level representations and automatically capture significant subgraphs without explicit annotations or prior knowledge in the context of Self-Supervised Learning. The fundamental idea behind our strategy is that, across the chemical domain, molecules share universal core subgraphs that can combine with specific significant subgraphs to robust representations of molecules.
- S-CGIB generates well-distinguished graph-level representations by compressing an input molecule graph into a graph core conditioned on specific significant subgraphs without using label information under the Subgraph-conditioned Graph Information Bottleneck principle.
- S-CGIB discover the significant subgraphs (functional groups) from the subgraph candidates (ego networks rooted at each node) through the attention-based interaction between the graph core and the ego networks under the graph reconstruction.
- Extensive experiments on molecule datasets across four domains demonstrate the superiority of S-CGIB.

## The S-CGIB is available at:
* [![GitHub](https://img.shields.io/badge/GitHub-Data%20&%20Code-9B9B9B?style=flat-square&logo=GitHub)](https://github.com/NSLab-CUK/S-CGIB)
* [![arXiv](https://img.shields.io/badge/arXiv-2308.09517-b31b1b?style=flat-square&logo=arxiv&logoColor=red)](https://arxiv.org/abs/2412.15589)


## Cite "S-CGIB" as: 

Please cite our [paper](https://arxiv.org/abs/2412.15589) if you find *S-CGIB* useful in your work:
```
@misc{hoang2024pretraininggraphneuralnetworks,
      title={Pre-training Graph Neural Networks on Molecules by Using Subgraph-Conditioned Graph Information Bottleneck}, 
      author={Van Thuy Hoang and O-Joun Lee},
      year={2024},
      eprint={2412.15589},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.15589}, 
}
```

:page_facing_up::woman_technologist::bookmark_tabs::label::black_nib:	

## Contributors: 

<a href="https://github.com/NSLab-CUK/Unified-Graph-Transformer/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=NSLab-CUK/Unified-Graph-Transformer" />
</a>

***

<a href="https://nslab-cuk.github.io/"><img src="https://github.com/NSLab-CUK/NSLab-CUK/raw/main/Logo_Dual_Wide.png"/></a>

***

