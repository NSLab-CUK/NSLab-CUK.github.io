---
layout: post
title:  Connector, an unified framework for graph representation learning
date:   2023-04-24 18:00:00 +0900
image:  Bib_Network.png
tags:   News
published: true
---

We provide [Connector](https://github.com/NSLab-CUK/Connector), an unified framework for graph representation learning. Connector is developed mainly based on Python language and PyTorch library. 

<p align="center"><img src="/images/Connector_architecture.jpg" style="width : 90%; max-width: 90%"></p>

Our framework comprises three main modules: graph loaders, base model modules, and graph representation learning modules. Graph Loader modules make it straightforward to handle different types of graphs. Since different types of graphs are stored in different file structures, we introduce four graph loaders to handle types of graphs, including homogeneous, heterogeneous, knowledge and signed graph loaders. There are two advantages of graph generation from stored files. First, loading the graph data from files with Graph Loaders makes building and handling the original datasets manageable. Second, our framework could help researchers who generated their own datasets integrate the datasets easily into our framework. The objective of the base module is to build general
tasks such as load models and load/save parameters. 
We develop this framework according to the settings of various graph embedding models. Thirteen graph embedding models have been implemented or modified, including DeepWalk, Node2Vec, Struct2Vec, HOPE, SiNE, Metapath2Vec, TransE, TransR, TransH, GCN, GraphSage, GIN, and GAT. 

In addition, we plan to mainly focus on introducing deep graph embedding models which understand the graph structure, such as local/global positional encoding and structural encodings. Positional encoding is a strategy that captures nodesâ€™ relative and absolute graph positions. In graphs, each node is commonly associated with a set of features, which can be used to represent the node in the graph. However, the position of a node in the graph is not represented in these features. There are several strategies to represent positional encoding to graph embedding models, including adding to node features as biases or combining with message information from neighbours nodes to target nodes. Therefore, we plan to integrate general, powerful GNNs and graph transformer models which could capture graph structure into Connector.
The framework is available at (https://github.com/NSLab-CUK/Connector).




